{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4781724,"sourceType":"datasetVersion","datasetId":2767755},{"sourceId":6555828,"sourceType":"datasetVersion","datasetId":3788284},{"sourceId":10042444,"sourceType":"datasetVersion","datasetId":6130416}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install -U ipywidgets\nfrom ultralytics import YOLO\nimport torch","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')\n\nmodel.train(\n    data='/kaggle/input/cv-project-files2/dataset.yaml',\n    epochs=75,                            # Number of training epochs\n    imgsz=640,                            # Image size\n    batch=32,                             # batch size\n    lr0=0.001,                             # initial learning rate\n    augment=True,                         # no data augmentation\n    dropout=0.2       ,                    # dropout to reduce overfitting\n    device=[0,1]\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-28T16:18:29.126358Z","iopub.status.idle":"2024-11-28T16:18:29.126672Z","shell.execute_reply.started":"2024-11-28T16:18:29.126504Z","shell.execute_reply":"2024-11-28T16:18:29.126518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from ultralytics import YOLO\n# resume training\n#model = YOLO('/kaggle/working/runs/detect/train/weights/last.pt')\n#model.train(resume=True)","metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2024-11-28T16:18:29.128214Z","iopub.status.idle":"2024-11-28T16:18:29.128651Z","shell.execute_reply.started":"2024-11-28T16:18:29.128424Z","shell.execute_reply":"2024-11-28T16:18:29.128446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folder = '/kaggle/input/large-license-plate-dataset/images/test/'\nmodel = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n\nresults = model(image_folder,stream=False)\noutput_folder = '/kaggle/working/test'\nok = 0\nskip = 0\nfor image in results:\n    device = image.boxes.xywh.device\n    suitable_crops = torch.empty((0,6), device=device)\n    for i in range(len(image)):\n        x, y, w, h = image.boxes.xywh[i].tolist() \n        if w > 50 and h > 20:\n            conf = image.boxes.conf[i]\n            keep_crop = torch.tensor([[x-w/2,y-h/2,x+w/2,y+h/2,conf,0]],device=device)\n            suitable_crops = torch.cat((suitable_crops,keep_crop))\n            ok+=1\n        else:\n            skip+=1\n    image.update(suitable_crops)\n    image.save_crop(output_folder)\n\nprint(\"ok\",ok,\"skip\",skip)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:18:29.130032Z","iopub.status.idle":"2024-11-28T16:18:29.130478Z","shell.execute_reply.started":"2024-11-28T16:18:29.130244Z","shell.execute_reply":"2024-11-28T16:18:29.130268Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to save the run : zip the folder from this command and then download the zip file\n#import shutil\n#shutil.make_archive(\"train_20\", 'zip', \"/kaggle/working/runs/detect/train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T16:18:29.131441Z","iopub.status.idle":"2024-11-28T16:18:29.131876Z","shell.execute_reply.started":"2024-11-28T16:18:29.131635Z","shell.execute_reply":"2024-11-28T16:18:29.131659Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## PaddleOCR","metadata":{}},{"cell_type":"code","source":"!pip install paddlepaddle-gpu\n!pip install paddleocr","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom paddleocr import PaddleOCR\nfrom PIL import Image\nimport pytesseract\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:48:28.209982Z","iopub.execute_input":"2024-12-04T19:48:28.210393Z","iopub.status.idle":"2024-12-04T19:48:32.326442Z","shell.execute_reply.started":"2024-12-04T19:48:28.210358Z","shell.execute_reply":"2024-12-04T19:48:32.325704Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def process_image(image):\n    scaled_image = cv2.resize(image, (400, 300))\n    gray_image = cv2.cvtColor(scaled_image, cv2.COLOR_BGR2GRAY)\n    gaussian_image = cv2.GaussianBlur(gray_image, (23, 23), 0)\n    \n    process_path = '/kaggle/working/PaddleOCR/preprocessed_license_plate.jpg'\n    cv2.imwrite(process_path, gaussian_image)\n    \n\ndef display_image(image, title=\"Image\", cmap='gray'):\n    plt.figure(figsize=(2, 2))  \n    plt.imshow(image, cmap=cmap) \n    plt.title(title) \n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:48:40.082008Z","iopub.execute_input":"2024-12-04T19:48:40.083039Z","iopub.status.idle":"2024-12-04T19:48:40.088066Z","shell.execute_reply.started":"2024-12-04T19:48:40.082987Z","shell.execute_reply":"2024-12-04T19:48:40.087170Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"csv_path = '/kaggle/input/license-plate-text-recognition-dataset/lpr.csv'  \nimages_folder = '/kaggle/input/license-plate-text-recognition-dataset/cropped_lps/cropped_lps'  \nprocess_path = '/kaggle/working/PaddleOCR/preprocessed_license_plate.jpg'\nocr = PaddleOCR(use_gpu=True,lang=\"en\",show_log=False, use_angle_cls=True)\n\ndata = pd.read_csv(csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:48:52.929746Z","iopub.execute_input":"2024-12-04T19:48:52.930084Z","iopub.status.idle":"2024-12-04T19:49:27.209724Z","shell.execute_reply.started":"2024-12-04T19:48:52.930053Z","shell.execute_reply":"2024-12-04T19:49:27.208734Z"}},"outputs":[{"name":"stdout","text":"download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3910/3910 [00:06<00:00, 603.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10000/10000 [00:05<00:00, 1963.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2138/2138 [00:15<00:00, 139.71it/s]","output_type":"stream"},{"name":"stdout","text":"[2024/12/04 19:49:24] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"[2024/12/04 19:49:25] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n[2024/12/04 19:49:26] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"correct_count = 0\nrecognized_count = 0\ntotal_count = 0\nalmost_count = 0\ni = 0\nfor index, row in tqdm(data.iterrows(), total=len(data), mininterval=2):    \n    if i < 10000:\n        i+=1\n        image_path = os.path.join(images_folder, row['images'])\n        ground_truth = row['labels']\n        image = cv2.imread(image_path)\n        \n        process_image(image)\n        result = ocr.ocr(process_path, rec=True)\n        if result and result[0]:\n            recognized_text = result[0][0][1][0]\n            recognized_text = re.sub(r'[^a-zA-Z0-9]', '', recognized_text)\n        else:\n            recognized_text = \"\"\n        \n        if recognized_text == ground_truth:\n            correct_count += 1\n            \n        total_count+=1\n    else:\n        break\n        \naccuracy = correct_count / total_count * 100\nprint(f\"Accuracy: {accuracy:.2f}% \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T19:49:27.211157Z","iopub.execute_input":"2024-12-04T19:49:27.211451Z","iopub.status.idle":"2024-12-04T19:55:37.314713Z","shell.execute_reply.started":"2024-12-04T19:49:27.211423Z","shell.execute_reply":"2024-12-04T19:55:37.313849Z"},"scrolled":true},"outputs":[{"name":"stderr","text":" 50%|█████     | 10000/20000 [06:10<06:10, 27.02it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 63.04% \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8}]}